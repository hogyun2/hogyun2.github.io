<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Hogyun Kim</title>

    <meta name="author" content="Hogyun Kim">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Hogyun Kim
                </p>
                <p>
                  I'm a PhD student at <a href="https://www.inha.ac.kr/kr/index.do">Inha University</a>, advised by <a href="https://sites.google.com/site/ygchocv/home">Younggun Cho</a> in <a href="https://sparolab.github.io/">SPARO Lab</a>. 
                  My research focuses on scalable and collaborative robot autonomy, enabling multiple robots to perceive, understand, and navigate shared environments together.
                </p>
                <p style="text-align:center">
                  <a href="hg.kim@inha.edu">Email</a> &nbsp;/&nbsp;
                  <a href="">CV</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/hogyun-kim/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/hogyun2/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/profile/hogyun.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile/hogyun.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
			
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>News</h2>
                  <ul style="list-style-type:disc; padding-left:20px;">
                    <!-- <li>[26.??.??] &nbsp; Submitted one paper to IEEE T-ITS (1st Author)</li> -->
                    <!-- <li>[26.??.??] &nbsp; Submitted one paper to IEEE T-FR (1st Author)</li> -->
                    <!-- <li>[26.??.??] &nbsp; Awarded SamsungHumantech Paper Award (1st Author)</li> -->
                    <!-- <li>[26.??.??] &nbsp; Submitted one paper to IJRR 2026 (1st Author)</li> -->
                    <li>[25.08.29] &nbsp; Awarded NRF Doctoral Research Fellowship (Principal Investigator)</li>
                    <li>[25.08.05] &nbsp; Invited for IEEE T-FR Special Issue (1st Author)</li>
                    <li>[25.06.16] &nbsp; Accepted one paper to IEEE/RSJ IROS 2025 (2nd Author)</li>
                    <li>[25.06.01] &nbsp; Accepted one paper to IEEE T-IV 2025 (2nd Author)</li>
                    <li>[25.04.30] &nbsp; Selected for Spotlight Talk at ICRA 2025 Workshop on Field Robotics (1st Author)</li>
                    <li>[25.01.28] &nbsp; Accepted two papers to IEEE ICRA 2025 (Co-Author)</li>
                    <li>[24.09.18] &nbsp; Accepted one paper to IEEE RA-L 2024 (1st Author)</li>
                    <li>[24.07.22] &nbsp; Accepted one paper to IEEE RA-L 2024 (1st Author)</li>
                    <li>[24.05.13] &nbsp; Awarded Best Paper Award (3rd Place) at ICRA 2024 Workshop on Future of Construction (2nd Author)</li>
                    <li>[23.05.16] &nbsp; Accepted one paper to IEEE ICRA 2024 Workshop on Radar in Robotics (1st Author)</li>
                    <li>[24.01.09] &nbsp; Accepted one paper to IEEE Sensors Letters 2024 (1st Author)</li>
                    <li>[23.05.16] &nbsp; Accepted one paper to IEEE ICRA 2023 Workshop on Future of Construction (1st Author)</li>
                    <li>[23.01.17] &nbsp; Accepted one paper to IEEE ICRA 2023 (1st Author)</li>
                    <li>[22.08.10] &nbsp; Accepted one paper to IEEE IROS 2022 Late-Breaking (1st Author)</li>
                  </ul>
                </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in robotics, SLAM, and autonomous systems. 
                  Most of my research is about enabling multiple robots to perceive and navigate shared environments, usually with multi-robot SLAM and place recognition. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <span class="papertitle">MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments </span>
              </a>
              <br>
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Seokhwan Jeong</a>,
              <strong>Hogyun Kim</strong>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Younggun Cho</a>
              <br>
              <em>IROS</em>, 2025
              <br>
              <a href="data/B3DO_ICCV_2011.bib">Project page</a> /
              <a href="data/B3DO_ICCV_2011.bib">arXiv</a> /
              <a href="data/B3DO_ICCV_2011.bib">paper</a> /
              <a href="">code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/uni_mapper.png" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <span class="papertitle">Uni-Mapper: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments </span>
              </a>
              <br>
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Gilhwan Kang</a>,
              <strong>Hogyun Kim</strong>,
              <a href="http://www.cs.berkeley.edu/%7Emfritz/">Byunghee Choi</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Seokhwan Jeong</a>
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Youngsik Shin</a>
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Younggun Cho</a>
              <br>
              <em>T-IV</em>, 2025
              <br>
              <a href="data/B3DO_ICCV_2011.bib">Project page</a> /
              <a href="data/B3DO_ICCV_2011.bib">arXiv</a> /
              <a href="data/B3DO_ICCV_2011.bib">paper</a> /
              <a href="">code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <span class="papertitle">SKiD-SLAM: Robust, Lightweight, and Distributed Multi-Robot LiDAR SLAM in Resource-Constrained Field Environments </span>
              </a>
              <br>
              <strong>Hogyun Kim</strong>,
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Jiwon Choi</a>,
              <a href="http://www.cs.berkeley.edu/%7Emfritz/">Juwon Kim</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Geonmo Yang</a>
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Dongjin Cho</a>
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Hyungtae Lim</a>
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Younggun Cho</a>
              <br>
              <em>RA-L</em>, 2025
              <br>
              <a href="data/B3DO_ICCV_2011.bib">Project page</a> /
              <a href="data/B3DO_ICCV_2011.bib">arXiv</a> /
              <a href="data/B3DO_ICCV_2011.bib">paper</a> /
              <a href="">code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>

            <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <span class="papertitle">ReFeree: Radar-based Lightweight and Robust Localization using Feature and Free space </span>
              </a>
              <br>
              <strong>Hogyun Kim</strong>,
              <a href="http://sergeykarayev.com/">Byunghee Choi</a>,
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Euncheol Choi</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Younggun Cho</a>
              <br>
              <em>RA-L</em>, 2024
              <br>
              <a href="data/B3DO_ICCV_2011.bib">Project page</a> /
              <a href="data/B3DO_ICCV_2011.bib">arXiv</a> /
              <a href="data/B3DO_ICCV_2011.bib">paper</a> /
              <a href="">code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <span class="papertitle">Narrowing your FOV with SOLiD: Spatially Organized and Lightweight Global Descriptor for FOV-constrained LiDAR Place Recognition </span>
              </a>
              <br>
              <strong>Hogyun Kim</strong>,
              <a href="http://sergeykarayev.com/">Jiwon Choi</a>,
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Taehu Sim</a>,
              <a href="http://www.cs.berkeley.edu/%7Emfritz/">Giseop Kim</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Younggun Cho</a>
              <br>
              <em>RA-L</em>, 2024
              <br>
              <a href="data/B3DO_ICCV_2011.bib">Project page</a> /
              <a href="data/B3DO_ICCV_2011.bib">arXiv</a> /
              <a href="data/B3DO_ICCV_2011.bib">paper</a> /
              <a href="">code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <span class="papertitle">DiTer: Diverse Terrain and Multimodal Dataset for Field Robot Navigation in Outdoor Environments </span>
              </a>
              <br>
              <a href="http://sergeykarayev.com/">Seokhwan Jeong*</a>,
              <strong>Hogyun Kim*</strong>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Younggun Cho</a>
              <br>
              <em>IEEE Sensors Letters</em>, 2024
              <br>
              <a href="data/B3DO_ICCV_2011.bib">Project page</a> /
              <a href="data/B3DO_ICCV_2011.bib">arXiv</a> /
              <a href="data/B3DO_ICCV_2011.bib">paper</a> /
              <a href="">code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <span class="papertitle">Robust Imaging Sonar-based Place Recognition and Localization in Underwater Environments</span>
              </a>
              <br>
              <strong>Hogyun Kim</strong>,
              <a href="http://sergeykarayev.com/">Gilhwan Kang</a>,
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Seokhwan Jeong</a>,
              <a href="http://www.cs.berkeley.edu/%7Emfritz/">Seungjun Ma</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Younggun Cho</a>
              <br>
              <em>ICRA</em>, 2023
              <br>
              <a href="data/B3DO_ICCV_2011.bib">Project page</a> /
              <a href="data/B3DO_ICCV_2011.bib">arXiv</a> /
              <a href="data/B3DO_ICCV_2011.bib">paper</a> /
              <a href="">code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>
	
          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>ETC</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Presentation</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://www.summerschoolprague.com/">KRoC OS on Cutting-Edge Tech. and App. for Autonomous Multi-Robot/Agent Collabo, 2024</a>
                <br>
                <a href="https://www.summerschoolprague.com/">IEEE RAS Summer School on Multi-Robot Systems, 2024</a>
                <br>
                <a href="https://2024.icros.org/">ICROS OS on Robotics and AI Tech. for Space and Extreme Environments, 2024</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://journals.sagepub.com/home/IJR/">Reviewer, IJRR 2026</a>
                <br>
                <a href="https://www.ieee-ras.org/publications/ra-l/">Reviewer, RAL 2025</a>
                <br>
                <a href="https://2026.ieee-icra.org/">Reviewer, ICRA 2026</a>
                <br>
                <a href="https://www.iros25.org/">Reviewer, IROS 2025</a>
                <br>
                <a href="https://ieeeoes.org/publication/ieee-joe/">Reviewer, IEEE JOE 2025</a>
                <br>
              </td>
            </tr>
						            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
